{
	"sourceDataInfo": {
		"newsID": "EC_M02_004537",
		"newsCategory": "경제",
		"newsSubcategory": "산업",
		"newsTitle": "베일 벗은 LG '초거대 AI' 엑사원...생태계 확장 탄력",
		"newsSubTitle": "LG, AI의 새로운 패러다임으로 부상하고 있는 초거대 AI 1년 동안 개발 기존 알파고를 능가하는 '엑사원(EXAONE)'...다양한 분야에서 창의적 활동 해외는 물론 국내 네이버·카카오 등 국내 초거대 AI 생태계 구축에 집중",
		"newsContent": "LG가 새 먹거리로 찜한 '초거대 인공지능(AI)' 엑사원(EXAONE)이 최근 모습을 드러냈다.\n이를 통해 글로벌 초거대 AI 생태계 확장에 나서겠다는 방침이다.\n17일 업계에 따르면 LG AI 연구원은 설립 1주년을 맞아 개최된 'LG AI 토크 콘서트'에서 엑사원을 공개하고 주요 연구 성과와 향후 계획을 밝혔다.\nLG는 지난해 AI의 새로운 패러다임으로 부상하고 있는 초거대 AI를 개발하겠다는 구상을 밝히며 전담 조직인 AI 연구원을 세웠다.\nAI연구원 출범과 함께 엑사원의 개발이 본격적으로 시작된 것이다.\n엑사원은 알파고를 능가하는 기술을 갖추고 있다.\n알파고가 한 가지 분야에서 정해진 답을 유추해내는 AI였다면 엑사원은 다양한 분야에서 창의적인 활동이 가능하다.\nLG그룹 관계자는 데일리임팩트에 \\\"알파고나 기존에 있던 AI들은 특정한 분야에만 특화돼 개발됐다면 엑사원은 모든 분야에 적용이 가능하다\\\"고 설명했다. '초거대 AI'는 전 세계가 열광하는 기술이다.\n이 기술을 선점하지 않으면 기술을 가진 경쟁사에 종속될 수밖에 없단 점에서다.\n초거대 AI는 인간의 뇌 구조를 닮은 AI다.\n대용량 연산이 가능한 컴퓨팅 인프라를 기반으로 대규모 데이터를 스스로 학습해 인간처럼 사고·학습·판단할 수 있다.\n인간 뇌의 신경세포를 연결하는 시냅스와 비슷한 인공신경망인 파라미터를 늘릴수록 많은 빅데이터 처리가 가능하다.\n그렇기에 기업들은 더 많은 양의 파라미터를 만들 수 있는 기술을 개발하기 위해 노력하고 있다.\n업계 관계자는 데일리임팩트에 \\\"파라미터의 개수가 많을수록 AI는 인간의 사고와 많이 비슷해진다\\\"며 \\\"기본적으로 파라미터가 많은 AI는 학습능력이 뛰어나다고 말할 수 있다\\\"고 설명했다.\n처음 대중들에게 공개된 것은 초거대 AI 언어모델인 'GPT-3'부터다.\n이는 일론머스크 테슬라 최고경영자(CEO)가 주도해 설립한 '오픈(Open)AI'가 만든 모델이다.\n당시 현존하는 최고 성능 AI 모델이었으며 LG는 이를 뛰어넘는 AI를 만들겠다고 나섰다.\nGPT-3는 1750억 개의 파라미터를 갖췄으며 소수의 지시만 가지고도 일을 해결할 수 있는 능력을 가졌다.\n세계적인 IT 기업 구글도 사람처럼 대화가 가능한 AI 람다(LaMdA)를 선보였으며 중국 하웨이는 최대 2000억개 수준의 중국어를 자연언어로 처리하는 판구알파를 선보였다.\n국내에서는 중국이나 미국에 종속되지 않기 위해 한국어 기반의 AI 생태계를 구축하겠다는 목표로 초거대 AI 시장에 뛰어들고 있다.\n네이버를 선두로 카카오, LG그룹이 잇따라 초거대 AI 모델을 선보였다.\n네이버는 'GPT-3'의 파라미터 개수를 뛰어넘은 초거대 AI 언어 모델 '하이클로바'를 공개했다.\n하이클로바는 2040억 개의 파라미터를 갖췄다.\nGPT-3보다 한국어 데이터를 6500배 이상 학습해 세계 최초 초거대 한국어 언어 모델로 평가받고 있다.\n카카오의 AI 연구 자회사 카카오브레인은 최근 초거대 AI 멀티모달 'minDALL-E'(민달리)를 최대 오픈소스 커뮤니티 깃허브에 공개했다.\n지난달 한국어 특화 AI 언어모델 'KoGPT'(GPT)를 공개한 지 한 달 만이었다.\n만달리는 이용자가 텍스트를 입력하면 실시간으로 원하는 이미지를 생성하는 모델로, 검색을 통해 이미지를 찾아내는 것이 아닌 AI가 스스로 이미지를 그릴 수 있다.\n한국어에 특화된 GPT 모델은 상품 리뷰 댓글의 평가가 긍정적인지 부정적인지 판별하거나 인과관계를 예측이 가능하다.\n또한 모델 성능 고도화에 집중하며 파라미터를 60억개에서 300억개까지 5배 늘렸다.\nLG의 엑사원은 국내 최대인 약 3000억개의 파라미터를 보유하고 있다.\n언어뿐 아니라 이미지와 영상에 이르기까지 인간의 의사 소통과 관련된 다양한 정보를 습득하고 다룰 수 있는 멀티 모달리티 능력을 갖췄다.\n또한 LG전자, LG화학, LG유플러스, LG CNS 등 LG 계열사들이 보유하고 있는 전문 데이터를 포함해 논문, 특허 등의 정제된 말뭉치들을 학습해 다양한 산업 분야에서 활용될 수 있도록 했다.\nLG그룹 관계자는 데일리임팩트에 \\\"초거대 AI 사업을 시작한 것은 1차적으로는 LG 계열사의 여러 사업들에 적용하는 것을 우선으로 생각했다\\\"며 \\\"2차적으로는 다른 산업과 융합시켜 업계에 전반적으로 AI를 확산시키는 것을 목표로 국내에서 초거대 AI 생태계를 구축할 것\\\"이라고 말했다.",
		"partNum": "P1",
		"useType": 0,
		"processType": "A",
		"processPattern": "99",
		"processLevel": "하",
		"sentenceCount": 33,
		"sentenceInfo": [
			{
				"sentenceNo": 1,
				"sentenceContent": "LG가 새 먹거리로 찜한 '초거대 인공지능(AI)' 엑사원(EXAONE)이 최근 모습을 드러냈다.",
				"sentenceSize": 54
			},
			{
				"sentenceNo": 2,
				"sentenceContent": "이를 통해 글로벌 초거대 AI 생태계 확장에 나서겠다는 방침이다.",
				"sentenceSize": 36
			},
			{
				"sentenceNo": 3,
				"sentenceContent": "17일 업계에 따르면 LG AI 연구원은 설립 1주년을 맞아 개최된 'LG AI 토크 콘서트'에서 엑사원을 공개하고 주요 연구 성과와 향후 계획을 밝혔다.",
				"sentenceSize": 86
			},
			{
				"sentenceNo": 4,
				"sentenceContent": "LG는 지난해 AI의 새로운 패러다임으로 부상하고 있는 초거대 AI를 개발하겠다는 구상을 밝히며 전담 조직인 AI 연구원을 세웠다.",
				"sentenceSize": 73
			},
			{
				"sentenceNo": 5,
				"sentenceContent": "AI연구원 출범과 함께 엑사원의 개발이 본격적으로 시작된 것이다.",
				"sentenceSize": 36
			},
			{
				"sentenceNo": 6,
				"sentenceContent": "엑사원은 알파고를 능가하는 기술을 갖추고 있다.",
				"sentenceSize": 26
			},
			{
				"sentenceNo": 7,
				"sentenceContent": "알파고가 한 가지 분야에서 정해진 답을 유추해내는 AI였다면 엑사원은 다양한 분야에서 창의적인 활동이 가능하다.",
				"sentenceSize": 62
			},
			{
				"sentenceNo": 8,
				"sentenceContent": "LG그룹 관계자는 데일리임팩트에 \\\"알파고나 기존에 있던 AI들은 특정한 분야에만 특화돼 개발됐다면 엑사원은 모든 분야에 적용이 가능하다\\\"고 설명했다. '초거대 AI'는 전 세계가 열광하는 기술이다.",
				"sentenceSize": 112
			},
			{
				"sentenceNo": 9,
				"sentenceContent": "이 기술을 선점하지 않으면 기술을 가진 경쟁사에 종속될 수밖에 없단 점에서다.",
				"sentenceSize": 43
			},
			{
				"sentenceNo": 10,
				"sentenceContent": "초거대 AI는 인간의 뇌 구조를 닮은 AI다.",
				"sentenceSize": 25
			},
			{
				"sentenceNo": 11,
				"sentenceContent": "대용량 연산이 가능한 컴퓨팅 인프라를 기반으로 대규모 데이터를 스스로 학습해 인간처럼 사고·학습·판단할 수 있다.",
				"sentenceSize": 63
			},
			{
				"sentenceNo": 12,
				"sentenceContent": "인간 뇌의 신경세포를 연결하는 시냅스와 비슷한 인공신경망인 파라미터를 늘릴수록 많은 빅데이터 처리가 가능하다.",
				"sentenceSize": 61
			},
			{
				"sentenceNo": 13,
				"sentenceContent": "그렇기에 기업들은 더 많은 양의 파라미터를 만들 수 있는 기술을 개발하기 위해 노력하고 있다.",
				"sentenceSize": 52
			},
			{
				"sentenceNo": 14,
				"sentenceContent": "업계 관계자는 데일리임팩트에 \\\"파라미터의 개수가 많을수록 AI는 인간의 사고와 많이 비슷해진다\\\"며 \\\"기본적으로 파라미터가 많은 AI는 학습능력이 뛰어나다고 말할 수 있다\\\"고 설명했다.",
				"sentenceSize": 106
			},
			{
				"sentenceNo": 15,
				"sentenceContent": "처음 대중들에게 공개된 것은 초거대 AI 언어모델인 'GPT-3'부터다.",
				"sentenceSize": 40
			},
			{
				"sentenceNo": 16,
				"sentenceContent": "이는 일론머스크 테슬라 최고경영자(CEO)가 주도해 설립한 '오픈(Open)AI'가 만든 모델이다.",
				"sentenceSize": 55
			},
			{
				"sentenceNo": 17,
				"sentenceContent": "당시 현존하는 최고 성능 AI 모델이었으며 LG는 이를 뛰어넘는 AI를 만들겠다고 나섰다.",
				"sentenceSize": 50
			},
			{
				"sentenceNo": 18,
				"sentenceContent": "GPT-3는 1750억 개의 파라미터를 갖췄으며 소수의 지시만 가지고도 일을 해결할 수 있는 능력을 가졌다.",
				"sentenceSize": 60
			},
			{
				"sentenceNo": 19,
				"sentenceContent": "세계적인 IT 기업 구글도 사람처럼 대화가 가능한 AI 람다(LaMdA)를 선보였으며 중국 하웨이는 최대 2000억개 수준의 중국어를 자연언어로 처리하는 판구알파를 선보였다.",
				"sentenceSize": 97
			},
			{
				"sentenceNo": 20,
				"sentenceContent": "국내에서는 중국이나 미국에 종속되지 않기 위해 한국어 기반의 AI 생태계를 구축하겠다는 목표로 초거대 AI 시장에 뛰어들고 있다.",
				"sentenceSize": 72
			},
			{
				"sentenceNo": 21,
				"sentenceContent": "네이버를 선두로 카카오, LG그룹이 잇따라 초거대 AI 모델을 선보였다.",
				"sentenceSize": 40
			},
			{
				"sentenceNo": 22,
				"sentenceContent": "네이버는 'GPT-3'의 파라미터 개수를 뛰어넘은 초거대 AI 언어 모델 '하이클로바'를 공개했다.",
				"sentenceSize": 55
			},
			{
				"sentenceNo": 23,
				"sentenceContent": "하이클로바는 2040억 개의 파라미터를 갖췄다.",
				"sentenceSize": 26
			},
			{
				"sentenceNo": 24,
				"sentenceContent": "GPT-3보다 한국어 데이터를 6500배 이상 학습해 세계 최초 초거대 한국어 언어 모델로 평가받고 있다.",
				"sentenceSize": 59
			},
			{
				"sentenceNo": 25,
				"sentenceContent": "카카오의 AI 연구 자회사 카카오브레인은 최근 초거대 AI 멀티모달 'minDALL-E'(민달리)를 최대 오픈소스 커뮤니티 깃허브에 공개했다.",
				"sentenceSize": 79
			},
			{
				"sentenceNo": 26,
				"sentenceContent": "지난달 한국어 특화 AI 언어모델 'KoGPT'(GPT)를 공개한 지 한 달 만이었다.",
				"sentenceSize": 48
			},
			{
				"sentenceNo": 27,
				"sentenceContent": "만달리는 이용자가 텍스트를 입력하면 실시간으로 원하는 이미지를 생성하는 모델로, 검색을 통해 이미지를 찾아내는 것이 아닌 AI가 스스로 이미지를 그릴 수 있다.",
				"sentenceSize": 89
			},
			{
				"sentenceNo": 28,
				"sentenceContent": "한국어에 특화된 GPT 모델은 상품 리뷰 댓글의 평가가 긍정적인지 부정적인지 판별하거나 인과관계를 예측이 가능하다.",
				"sentenceSize": 64
			},
			{
				"sentenceNo": 29,
				"sentenceContent": "또한 모델 성능 고도화에 집중하며 파라미터를 60억개에서 300억개까지 5배 늘렸다.",
				"sentenceSize": 47
			},
			{
				"sentenceNo": 30,
				"sentenceContent": "LG의 엑사원은 국내 최대인 약 3000억개의 파라미터를 보유하고 있다.",
				"sentenceSize": 40
			},
			{
				"sentenceNo": 31,
				"sentenceContent": "언어뿐 아니라 이미지와 영상에 이르기까지 인간의 의사 소통과 관련된 다양한 정보를 습득하고 다룰 수 있는 멀티 모달리티 능력을 갖췄다.",
				"sentenceSize": 75
			},
			{
				"sentenceNo": 32,
				"sentenceContent": "또한 LG전자, LG화학, LG유플러스, LG CNS 등 LG 계열사들이 보유하고 있는 전문 데이터를 포함해 논문, 특허 등의 정제된 말뭉치들을 학습해 다양한 산업 분야에서 활용될 수 있도록 했다.",
				"sentenceSize": 110
			},
			{
				"sentenceNo": 33,
				"sentenceContent": "LG그룹 관계자는 데일리임팩트에 \\\"초거대 AI 사업을 시작한 것은 1차적으로는 LG 계열사의 여러 사업들에 적용하는 것을 우선으로 생각했다\\\"며 \\\"2차적으로는 다른 산업과 융합시켜 업계에 전반적으로 AI를 확산시키는 것을 목표로 국내에서 초거대 AI 생태계를 구축할 것\\\"이라고 말했다.",
				"sentenceSize": 162
			}
		]
	},
	"labeledDataInfo": {
		"newTitle": "NHN페이코, 750억 투자 유치...금융상품 개발 박차",
		"clickbaitClass": 0,
		"referSentenceInfo": [
			{
				"sentenceNo": 1,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 2,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 3,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 4,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 5,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 6,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 7,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 8,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 9,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 10,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 11,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 12,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 13,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 14,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 15,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 16,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 17,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 18,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 19,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 20,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 21,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 22,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 23,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 24,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 25,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 26,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 27,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 28,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 29,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 30,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 31,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 32,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 33,
				"referSentenceyn": "N"
			}
		]
	}
}