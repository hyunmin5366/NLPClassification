{
	"sourceDataInfo": {
		"newsID": "IS_M10_349777",
		"newsCategory": "IT&과학",
		"newsSubcategory": "IT/과학, 헬스 > 게임",
		"newsTitle": "엔씨, AI 윤리 개선 위한 'AI 프레임워크' 시리즈 공개",
		"newsSubTitle": "null",
		"newsContent": "엔씨소프트가 AI(인공지능) 시대 리더십과 윤리 개선을 위해 마련한 'AI 프레임워크' 시리즈를 자사 유튜브와 블로그를 통해 공개했다고 30일 밝혔다.\nAI 프레임워크 시리즈는 엔씨가 ESG(환경·사회·지배구조) 경영 핵심 분야 중 하나인 'AI 시대의 리더십과 윤리'를 위해 준비한 연중 기획 프로젝트다.\n하버드대학교, 스탠퍼드대학교, 매사추세츠공과대학(MIT) 등 세계적인 석학과의 토론을 통해 AI 기술을 바라보는 새로운 관점과 방향을 제시한다.\n저명한 AI 연구진을 비롯해 정치학, 철학 등 분야별 석학과 대담을 이어갈 예정이다.\n이번에 공개된 것은 윤송이 엔씨 최고전략책임자(CSO)와 스탠퍼드 인간 중심 AI 연구소 페이-페이 리 공동소장의 대담 영상이다.\n▲AI 시대가 이끄는 윤리의 혁명 ▲규제와 혁신의 사이에서 ▲AI 시대와 인류의 진화 ▲국가와 문화를 초월하는 협력 등 내용을 순차적으로 다룬다.\n페이-페이 리 스탠퍼드 HAI 공동소장은 대담을 통해 \\\"AI 기술을 공학적 접근뿐 아니라 윤리, 교육, 철학 등 새로운 관점으로 바라봐야 한다\\\"고 주장했다.\n이와 더불어 연구소 설립 배경 및 운영 철학, 학제적 연구의 필요성, 인류를 위한 AI 기술 개발 방향 등에 대한 생각을 전했다.\n현재 스탠퍼드 HAI 자문 위원을 맡은 윤송이 CSO는 과거부터 AI 기술에 대한 화두를 던지고 방향성을 제시했다.\n지난 2019년 11월 엔씨 블로그를 통해 AI 시대의 윤리를 주제로 칼럼을 게재했다.\n지난해 1월에는 미국 아스펜 연구소가 주최한 '인공적인 친밀함' 포럼에 참석해 \\\"인간과 AI 사이 인공적으로 설계된 친밀함을 경계하며 우리 사회의 정책적 가이드라인이 필요하다\\\"고 말한 바 있다.\n엔씨는 AI 기술의 윤리적 사용을 위해 학제적 접근이 필요함을 인식하고 지난해부터 스탠퍼드대학교, 매사추세츠공과대학의 AI 윤리 커리큘럼의 개발을 함께 고민하고 있다.\n올해는 하버드대학까지 확대해 이를 일반 대중에게 공개할 수 있도록 힘쓰고 있다.",
		"partNum": "P1",
		"useType": 1,
		"processType": "A",
		"processPattern": "00",
		"processLevel": "하",
		"sentenceCount": 13,
		"sentenceInfo": [
			{
				"sentenceNo": 1,
				"sentenceContent": "엔씨소프트가 AI(인공지능) 시대 리더십과 윤리 개선을 위해 마련한 'AI 프레임워크' 시리즈를 자사 유튜브와 블로그를 통해 공개했다고 30일 밝혔다.",
				"sentenceSize": 84
			},
			{
				"sentenceNo": 2,
				"sentenceContent": "AI 프레임워크 시리즈는 엔씨가 ESG(환경·사회·지배구조) 경영 핵심 분야 중 하나인 'AI 시대의 리더십과 윤리'를 위해 준비한 연중 기획 프로젝트다.",
				"sentenceSize": 86
			},
			{
				"sentenceNo": 3,
				"sentenceContent": "하버드대학교, 스탠퍼드대학교, 매사추세츠공과대학(MIT) 등 세계적인 석학과의 토론을 통해 AI 기술을 바라보는 새로운 관점과 방향을 제시한다.",
				"sentenceSize": 80
			},
			{
				"sentenceNo": 4,
				"sentenceContent": "저명한 AI 연구진을 비롯해 정치학, 철학 등 분야별 석학과 대담을 이어갈 예정이다.",
				"sentenceSize": 47
			},
			{
				"sentenceNo": 5,
				"sentenceContent": "이번에 공개된 것은 윤송이 엔씨 최고전략책임자(CSO)와 스탠퍼드 인간 중심 AI 연구소 페이-페이 리 공동소장의 대담 영상이다.",
				"sentenceSize": 72
			},
			{
				"sentenceNo": 6,
				"sentenceContent": "▲AI 시대가 이끄는 윤리의 혁명 ▲규제와 혁신의 사이에서 ▲AI 시대와 인류의 진화 ▲국가와 문화를 초월하는 협력 등 내용을 순차적으로 다룬다.",
				"sentenceSize": 81
			},
			{
				"sentenceNo": 7,
				"sentenceContent": "페이-페이 리 스탠퍼드 HAI 공동소장은 대담을 통해 \\\"AI 기술을 공학적 접근뿐 아니라 윤리, 교육, 철학 등 새로운 관점으로 바라봐야 한다\\\"고 주장했다.",
				"sentenceSize": 89
			},
			{
				"sentenceNo": 8,
				"sentenceContent": "이와 더불어 연구소 설립 배경 및 운영 철학, 학제적 연구의 필요성, 인류를 위한 AI 기술 개발 방향 등에 대한 생각을 전했다.",
				"sentenceSize": 72
			},
			{
				"sentenceNo": 9,
				"sentenceContent": "현재 스탠퍼드 HAI 자문 위원을 맡은 윤송이 CSO는 과거부터 AI 기술에 대한 화두를 던지고 방향성을 제시했다.",
				"sentenceSize": 64
			},
			{
				"sentenceNo": 10,
				"sentenceContent": "지난 2019년 11월 엔씨 블로그를 통해 AI 시대의 윤리를 주제로 칼럼을 게재했다.",
				"sentenceSize": 48
			},
			{
				"sentenceNo": 11,
				"sentenceContent": "지난해 1월에는 미국 아스펜 연구소가 주최한 '인공적인 친밀함' 포럼에 참석해 \\\"인간과 AI 사이 인공적으로 설계된 친밀함을 경계하며 우리 사회의 정책적 가이드라인이 필요하다\\\"고 말한 바 있다.",
				"sentenceSize": 110
			},
			{
				"sentenceNo": 12,
				"sentenceContent": "엔씨는 AI 기술의 윤리적 사용을 위해 학제적 접근이 필요함을 인식하고 지난해부터 스탠퍼드대학교, 매사추세츠공과대학의 AI 윤리 커리큘럼의 개발을 함께 고민하고 있다.",
				"sentenceSize": 93
			},
			{
				"sentenceNo": 13,
				"sentenceContent": "올해는 하버드대학까지 확대해 이를 일반 대중에게 공개할 수 있도록 힘쓰고 있다.",
				"sentenceSize": 44
			}
		]
	},
	"labeledDataInfo": {
		"newTitle": "엔씨, AI 윤리 개선 위한 'AI 프레임워크' 시리즈 공개",
		"clickbaitClass": 1,
		"referSentenceInfo": [
			{
				"sentenceNo": 1,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 2,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 3,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 4,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 5,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 6,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 7,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 8,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 9,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 10,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 11,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 12,
				"referSentenceyn": "N"
			},
			{
				"sentenceNo": 13,
				"referSentenceyn": "N"
			}
		]
	}
}